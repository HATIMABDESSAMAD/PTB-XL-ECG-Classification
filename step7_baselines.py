"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 7: BASELINES & COMPARAISON - PTB-XL Wide+Deep
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EntraÃ®ne et compare 3 architectures:
  [A] Deep Only  - Signaux ECG seulement
  [B] Wide Only  - Features tabulaires seulement (XGBoost + MLP)
  [C] Wide+Deep  - Architecture hybride (best)

MÃ©triques: AUC macro/micro, AUPRC, F1
Analyse: Effet qualitÃ© signal (RPeaks_ok) sur performances
"""

import pandas as pd
import numpy as np
from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, classification_report
import json
from pathlib import Path

print("=" * 100)
print("STEP 7: BASELINES & COMPARAISON")
print("=" * 100)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. BASELINE B: WIDE ONLY avec XGBoost
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def train_wide_baseline_xgboost():
    """Baseline Wide avec XGBoost (multi-label)"""
    print("\n[Baseline B: Wide Only - XGBoost]")
    
    try:
        import xgboost as xgb
        from sklearn.multioutput import MultiOutputClassifier
    except ImportError:
        print("  âœ— XGBoost non installÃ©")
        print("  â†’ pip install xgboost")
        return None
    
    # Charger donnÃ©es Wide
    data_train = np.load('preprocessed_wide/W_train.npz', allow_pickle=True)
    data_val = np.load('preprocessed_wide/W_val.npz', allow_pickle=True)
    data_test = np.load('preprocessed_wide/W_test.npz', allow_pickle=True)
    
    W_train = data_train['features']
    W_val = data_val['features']
    W_test = data_test['features']
    
    # Charger labels (5 superclasses)
    with open('label_config.json', 'r') as f:
        label_config = json.load(f)
    
    df_labels = pd.read_csv('ptbxl_with_labels_expanded.csv', index_col='ecg_id')
    
    label_cols = label_config['superclass_cols']
    
    y_train = df_labels.loc[data_train['ecg_ids'], label_cols].values
    y_val = df_labels.loc[data_val['ecg_ids'], label_cols].values
    y_test = df_labels.loc[data_test['ecg_ids'], label_cols].values
    
    print(f"  â€¢ Train: {W_train.shape}")
    print(f"  â€¢ Test : {W_test.shape}")
    print(f"  â€¢ Classes: {len(label_cols)}")
    
    # EntraÃ®ner XGBoost (multi-output)
    print("\n  EntraÃ®nement XGBoost...")
    xgb_model = xgb.XGBClassifier(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        random_state=42,
        tree_method='hist',
        eval_metric='logloss'
    )
    
    multi_xgb = MultiOutputClassifier(xgb_model, n_jobs=-1)
    multi_xgb.fit(W_train, y_train)
    
    # PrÃ©dictions
    y_pred_proba_test = multi_xgb.predict_proba(W_test)
    
    # Extraire probas classe positive
    y_pred_proba_test = np.array([y_pred_proba_test[i][:, 1] for i in range(len(label_cols))]).T
    
    # MÃ©triques
    auc_macro = roc_auc_score(y_test, y_pred_proba_test, average='macro')
    auc_micro = roc_auc_score(y_test, y_pred_proba_test, average='micro')
    auprc_macro = average_precision_score(y_test, y_pred_proba_test, average='macro')
    
    # PrÃ©dictions binaires (threshold 0.5)
    y_pred_binary = (y_pred_proba_test > 0.5).astype(int)
    f1_macro = f1_score(y_test, y_pred_binary, average='macro', zero_division=0)
    
    print(f"\n  âœ“ RÃ©sultats XGBoost:")
    print(f"    â€¢ AUC macro: {auc_macro:.4f}")
    print(f"    â€¢ AUC micro: {auc_micro:.4f}")
    print(f"    â€¢ AUPRC    : {auprc_macro:.4f}")
    print(f"    â€¢ F1 macro : {f1_macro:.4f}")
    
    return {
        'model_type': 'XGBoost',
        'auc_macro': auc_macro,
        'auc_micro': auc_micro,
        'auprc_macro': auprc_macro,
        'f1_macro': f1_macro
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. COMPARAISON AVEC RÃ‰SULTATS PyTorch (A, C)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compare_baselines():
    """Compare les 3 baselines"""
    print("\n" + "=" * 100)
    print("COMPARAISON DES BASELINES")
    print("=" * 100)
    
    results = []
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # A. Deep Only (depuis step6_training.py)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # NOTE: doit Ãªtre exÃ©cutÃ© manuellement avec config.model_type = 'deep_only'
    print("\n[A] Deep Only:")
    print("  âš ï¸  ExÃ©cuter step6_training.py avec Config.model_type = 'deep_only'")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # B. Wide Only (XGBoost + MLP)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n[B] Wide Only:")
    xgb_results = train_wide_baseline_xgboost()
    if xgb_results:
        results.append(xgb_results)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # C. Wide+Deep (depuis step6_training.py)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n[C] Wide+Deep:")
    print("  âš ï¸  ExÃ©cuter step6_training.py avec Config.model_type = 'wide_deep'")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Charger rÃ©sultats existants (si disponibles)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    results_dir = Path('results')
    if results_dir.exists():
        for result_file in results_dir.glob('results_*.json'):
            with open(result_file, 'r') as f:
                data = json.load(f)
                results.append({
                    'model_type': data['config']['model_type'],
                    'auc_macro': data['test_metrics']['auc_macro'],
                    'auc_micro': data['test_metrics']['auc_micro'],
                    'auprc_macro': data['test_metrics']['auprc_macro']
                })
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Tableau comparatif
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if len(results) > 0:
        print("\n" + "=" * 100)
        print("TABLEAU COMPARATIF")
        print("=" * 100)
        
        df_results = pd.DataFrame(results)
        print(df_results.to_string(index=False))
        
        # Identifier meilleur
        best_idx = df_results['auc_macro'].idxmax()
        best_model = df_results.loc[best_idx, 'model_type']
        
        print(f"\nğŸ† MEILLEUR MODÃˆLE: {best_model}")
        print(f"   AUC macro: {df_results.loc[best_idx, 'auc_macro']:.4f}")
    
    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. ANALYSE QUALITÃ‰ SIGNAL (RPeaks_ok)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_quality_effect():
    """Analyse l'effet de la qualitÃ© signal sur performances"""
    print("\n" + "=" * 100)
    print("ANALYSE QUALITÃ‰ SIGNAL (RPeaks_ok)")
    print("=" * 100)
    
    # Charger features Wide
    df_wide = pd.read_csv('ptbxl_wide_features.csv', index_col='ecg_id')
    
    # Charger labels test
    data_test = np.load('preprocessed_wide/W_test.npz', allow_pickle=True)
    ecg_ids_test = data_test['ecg_ids']
    
    # Filtrer Wide features test
    df_wide_test = df_wide.loc[ecg_ids_test]
    
    # SÃ©parer par qualitÃ© R-peaks
    good_quality = df_wide_test[df_wide_test['rpeaks_ok'] == 1]
    bad_quality = df_wide_test[df_wide_test['rpeaks_ok'] == 0]
    
    print(f"\nğŸ“Š RÃ‰PARTITION QUALITÃ‰ (Test):")
    print(f"  â€¢ Bonne qualitÃ© (RPeaks_ok=1): {len(good_quality):,} ECG ({len(good_quality)/len(df_wide_test)*100:.1f}%)")
    print(f"  â€¢ Mauvaise qualitÃ© (RPeaks_ok=0): {len(bad_quality):,} ECG ({len(bad_quality)/len(df_wide_test)*100:.1f}%)")
    
    print(f"\nğŸ’¡ RECOMMANDATIONS:")
    print("  1. Ã‰valuer modÃ¨les sÃ©parÃ©ment sur bonne/mauvaise qualitÃ©")
    print("  2. ConsidÃ©rer filtrage qualitÃ© en prÃ©-processing")
    print("  3. Utiliser RPeaks_ok comme feature Wide (dÃ©jÃ  inclus)")
    print("  4. Analyse per-class: certaines pathologies plus sensibles au bruit")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. GUIDE COMPLET D'EXÃ‰CUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def print_execution_guide():
    """Guide complet pour exÃ©cuter le pipeline"""
    print("\n" + "=" * 100)
    print("GUIDE COMPLET D'EXÃ‰CUTION - PTB-XL Wide+Deep Pipeline")
    print("=" * 100)
    
    guide = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    PIPELINE COMPLET (7 STEPS)                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

STEP 1: LABEL ENGINEERING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
$ python step1_label_engineering.py

Sortie: 
  âœ“ ptbxl_with_labels_expanded.csv (metadata + y__<CODE> + y_SUP__<CLASS>)
  âœ“ label_config.json (liste codes pour modÃ¨le)


STEP 2: SIGNAL CLEANING (NeuroKit2) â€” ~20-30 minutes
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
$ pip install neurokit2 wfdb
$ python step2_signal_cleaning.py

Sortie:
  âœ“ cleaned_signals_100hz/ (21,799 fichiers .npz de ~10 KB)
  âœ“ ptbxl_with_cleaned_signals.csv


STEP 3: WIDE FEATURES EXTRACTION â€” ~10-15 minutes
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
$ python step3_wide_features_extraction.py

Sortie:
  âœ“ ptbxl_wide_features.csv (~42 features: clinical + metadata)


STEP 4: WIDE PREPROCESSING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
$ python step4_wide_preprocessing.py

Sortie:
  âœ“ preprocessed_wide/W_train.npz
  âœ“ preprocessed_wide/W_val.npz
  âœ“ preprocessed_wide/W_test.npz
  âœ“ preprocessed_wide/wide_preprocessor.pkl


STEP 5: ARCHITECTURE TEST
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
$ pip install torch
$ python step5_wide_deep_model.py

Sortie:
  âœ“ Test forward pass architecture


STEP 6: TRAINING (3 configurations) â€” ~2-5 heures selon GPU
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Configuration A: Deep Only
  â€¢ Ã‰diter step6_training.py:
    Config.model_type = 'deep_only'
    Config.task_mode = '5superclass'  # ou '71codes'
  â€¢ $ python step6_training.py
  â€¢ Sortie: models/best_model_deep_only.pth

Configuration B: Wide Only (XGBoost)
  â€¢ $ python step7_baselines.py
  â€¢ Sortie: rÃ©sultats XGBoost imprimÃ©s

Configuration C: Wide+Deep (RECOMMANDÃ‰)
  â€¢ Ã‰diter step6_training.py:
    Config.model_type = 'wide_deep'
    Config.task_mode = '5superclass'
  â€¢ $ python step6_training.py
  â€¢ Sortie: models/best_model_wide_deep.pth


STEP 7: COMPARAISON & ANALYSE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
$ python step7_baselines.py

Sortie:
  âœ“ Tableau comparatif 3 baselines
  âœ“ Analyse qualitÃ© signal (RPeaks_ok)


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    RÃ‰SULTATS ATTENDUS (CinC 2020)                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

5 Superclasses (NORM/MI/STTC/CD/HYP):
  â€¢ Deep Only   : AUC macro ~0.85-0.88
  â€¢ Wide Only   : AUC macro ~0.75-0.80  (XGBoost)
  â€¢ Wide+Deep   : AUC macro ~0.88-0.92  â­ MEILLEUR

71 Codes SCP:
  â€¢ Deep Only   : AUC macro ~0.78-0.82
  â€¢ Wide Only   : AUC macro ~0.65-0.70
  â€¢ Wide+Deep   : AUC macro ~0.80-0.85  â­ MEILLEUR


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    DÃ‰PENDANCES REQUISES                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

$ pip install pandas numpy scikit-learn wfdb neurokit2 torch xgboost tqdm


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    STRUCTURE FICHIERS FINAUX                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ptb-xl-dataset/
â”œâ”€â”€ step1_label_engineering.py
â”œâ”€â”€ step2_signal_cleaning.py
â”œâ”€â”€ step3_wide_features_extraction.py
â”œâ”€â”€ step4_wide_preprocessing.py
â”œâ”€â”€ step5_wide_deep_model.py
â”œâ”€â”€ step6_training.py
â”œâ”€â”€ step7_baselines.py
â”œâ”€â”€ ptbxl_with_labels_expanded.csv
â”œâ”€â”€ label_config.json
â”œâ”€â”€ cleaned_signals_100hz/
â”‚   â”œâ”€â”€ X_clean_00001.npz
â”‚   â””â”€â”€ ...
â”œâ”€â”€ preprocessed_wide/
â”‚   â”œâ”€â”€ W_train.npz
â”‚   â”œâ”€â”€ W_val.npz
â”‚   â”œâ”€â”€ W_test.npz
â”‚   â””â”€â”€ wide_preprocessor.pkl
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model_deep_only.pth
â”‚   â”œâ”€â”€ best_model_wide_only.pth
â”‚   â””â”€â”€ best_model_wide_deep.pth
â””â”€â”€ results/
    â”œâ”€â”€ results_deep_only.json
    â”œâ”€â”€ results_wide_only.json
    â””â”€â”€ results_wide_deep.json


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    RÃ‰FÃ‰RENCES                                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[1] Wagner et al. (2020) - PTB-XL Dataset, Scientific Data
[2] CinC Challenge 2020 - Classification of 12-lead ECGs
[3] NeuroKit2 - Makowski et al. (2021)
[4] Wide & Deep Learning - Cheng et al. (2016), Google

"""
    print(guide)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. EXÃ‰CUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    # Guide d'exÃ©cution
    print_execution_guide()
    
    # Comparaison baselines
    print("\n" + "=" * 100)
    print("EXÃ‰CUTION BASELINE B: Wide Only (XGBoost)")
    print("=" * 100)
    
    try:
        compare_baselines()
        analyze_quality_effect()
    except Exception as e:
        print(f"\nâš ï¸  Erreur: {e}")
        print("Assurez-vous que tous les steps prÃ©cÃ©dents ont Ã©tÃ© exÃ©cutÃ©s.")
    
    print("\n" + "=" * 100)
    print("âœ… PIPELINE PTB-XL WIDE+DEEP COMPLET")
    print("=" * 100)
