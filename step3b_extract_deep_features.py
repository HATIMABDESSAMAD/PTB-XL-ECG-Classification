"""
=================================================================
STEP 3B: EXTRACTION FEATURES DEEP (CNN + TRANSFORMER)
=================================================================

Extrait les 64 features latentes du DeepBranch (CNN + Transformer)
pour chaque ECG en utilisant le modÃ¨le prÃ©-entraÃ®nÃ©.

INPUT:
  â€¢ cleaned_signals_100hz/*.npz (21,481 signaux)
  â€¢ models/best_model.pth (modÃ¨le entraÃ®nÃ©)

OUTPUT:
  â€¢ deep_features/deep_features_train.npz (64 features Ã— 17,182)
  â€¢ deep_features/deep_features_val.npz (64 features Ã— 2,137)
  â€¢ deep_features/deep_features_test.npz (64 features Ã— 2,162)
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from pathlib import Path
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# Import modÃ¨le
from step5_wide_deep_model import DeepBranch

print("=" * 100)
print("STEP 3B: EXTRACTION FEATURES DEEP (CNN + Transformer)")
print("=" * 100)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SIGNALS_DIR = Path('cleaned_signals_100hz')
MODEL_PATH = 'models/best_model.pth'
LABELS_FILE = 'ptbxl_from_excel_consolidated.csv'
OUTPUT_DIR = Path('deep_features')
OUTPUT_DIR.mkdir(exist_ok=True)

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
BATCH_SIZE = 32

print(f"\nâš™ï¸  CONFIGURATION:")
print(f"  â€¢ Device: {DEVICE}")
print(f"  â€¢ Batch size: {BATCH_SIZE}")
print(f"  â€¢ Output: {OUTPUT_DIR}/")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. CHARGEMENT MODÃˆLE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print(f"\n[1/4] Chargement modÃ¨le prÃ©-entraÃ®nÃ©...")

# CrÃ©er DeepBranch
deep_branch = DeepBranch(
    n_leads=12,
    seq_len=1000,
    d_model=256,
    transformer_heads=8,
    transformer_layers=8,
    deep_features_dim=64,
    dropout=0.1
).to(DEVICE)

# Charger poids depuis modÃ¨le complet
if Path(MODEL_PATH).exists():
    checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
    
    # Extraire uniquement les poids du DeepBranch
    deep_state_dict = {}
    for k, v in checkpoint.items():
        if k.startswith('deep_branch.'):
            # Retirer le prÃ©fixe 'deep_branch.'
            new_key = k.replace('deep_branch.', '')
            deep_state_dict[new_key] = v
    
    deep_branch.load_state_dict(deep_state_dict)
    print(f"  âœ“ ModÃ¨le chargÃ© depuis {MODEL_PATH}")
else:
    print(f"  âš ï¸  ModÃ¨le non trouvÃ©, utilisation modÃ¨le non-entraÃ®nÃ©")

deep_branch.eval()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. CHARGEMENT DONNÃ‰ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print(f"\n[2/4] Chargement dataset...")

df = pd.read_csv(LABELS_FILE, index_col='ecg_id')

# SÃ©parer par strat_fold
df_train = df[df['strat_fold'] <= 8].copy()
df_val = df[df['strat_fold'] == 9].copy()
df_test = df[df['strat_fold'] == 10].copy()

print(f"  âœ“ Train: {len(df_train)} ECG")
print(f"  âœ“ Val  : {len(df_val)} ECG")
print(f"  âœ“ Test : {len(df_test)} ECG")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. EXTRACTION FEATURES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_features_batch(ecg_ids, batch_size=32):
    """Extrait features Deep pour un batch d'ECG IDs"""
    all_features = []
    valid_ids = []
    
    # Traiter par batches
    for i in tqdm(range(0, len(ecg_ids), batch_size), desc="  Extracting"):
        batch_ids = ecg_ids[i:i+batch_size]
        batch_signals = []
        batch_valid_ids = []
        
        # Charger signaux du batch
        for ecg_id in batch_ids:
            signal_path = SIGNALS_DIR / f"X_clean_{ecg_id:05d}.npz"
            try:
                data = np.load(signal_path)
                signal = data['signal']  # (12, 1000)
                batch_signals.append(signal)
                batch_valid_ids.append(ecg_id)
            except:
                # Signal manquant
                continue
        
        if len(batch_signals) == 0:
            continue
        
        # Convertir en tensor
        X_batch = torch.from_numpy(np.array(batch_signals)).float().to(DEVICE)
        
        # Extraire features
        with torch.no_grad():
            deep_feats = deep_branch(X_batch)  # (batch, 64)
        
        all_features.append(deep_feats.cpu().numpy())
        valid_ids.extend(batch_valid_ids)
    
    # ConcatÃ©ner tous les batches
    if len(all_features) > 0:
        features = np.vstack(all_features)
        return features, np.array(valid_ids)
    else:
        return np.array([]), np.array([])


print(f"\n[3/4] Extraction features Deep...")

# Train
print(f"\n  Train:")
deep_train, ids_train = extract_features_batch(df_train.index.values, BATCH_SIZE)
print(f"    âœ“ Shape: {deep_train.shape}")

# Val
print(f"\n  Val:")
deep_val, ids_val = extract_features_batch(df_val.index.values, BATCH_SIZE)
print(f"    âœ“ Shape: {deep_val.shape}")

# Test
print(f"\n  Test:")
deep_test, ids_test = extract_features_batch(df_test.index.values, BATCH_SIZE)
print(f"    âœ“ Shape: {deep_test.shape}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. SAUVEGARDE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print(f"\n[4/4] Sauvegarde...")

np.savez_compressed(
    OUTPUT_DIR / 'deep_features_train.npz',
    features=deep_train,
    ecg_ids=ids_train
)

np.savez_compressed(
    OUTPUT_DIR / 'deep_features_val.npz',
    features=deep_val,
    ecg_ids=ids_val
)

np.savez_compressed(
    OUTPUT_DIR / 'deep_features_test.npz',
    features=deep_test,
    ecg_ids=ids_test
)

print(f"  âœ“ SauvegardÃ©: {OUTPUT_DIR}/deep_features_train.npz")
print(f"  âœ“ SauvegardÃ©: {OUTPUT_DIR}/deep_features_val.npz")
print(f"  âœ“ SauvegardÃ©: {OUTPUT_DIR}/deep_features_test.npz")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. RÃ‰SUMÃ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 100)
print("STATISTIQUES FINALES")
print("=" * 100)

print(f"\nğŸ“Š FEATURES DEEP EXTRAITES:")
print(f"  â€¢ Train: {deep_train.shape[0]} ECG Ã— {deep_train.shape[1]} features")
print(f"  â€¢ Val  : {deep_val.shape[0]} ECG Ã— {deep_val.shape[1]} features")
print(f"  â€¢ Test : {deep_test.shape[0]} ECG Ã— {deep_test.shape[1]} features")

print(f"\nğŸ’¾ FICHIERS GÃ‰NÃ‰RÃ‰S:")
print(f"  â€¢ {OUTPUT_DIR}/deep_features_train.npz")
print(f"  â€¢ {OUTPUT_DIR}/deep_features_val.npz")
print(f"  â€¢ {OUTPUT_DIR}/deep_features_test.npz")

print(f"\nâœ… STEP 3B TERMINÃ‰")
print(f"   Prochaine Ã©tape: step4b_merge_all_features.py")
print("=" * 100)
