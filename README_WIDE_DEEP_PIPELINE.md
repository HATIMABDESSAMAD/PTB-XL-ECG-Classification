# PTB-XL Wide+Deep Pipeline - Installation & ExÃ©cution

## ğŸ“‹ Vue d'ensemble

Pipeline complet pour classification ECG multi-label sur PTB-XL avec architecture **Wide+Deep**:
- **Deep Branch**: CNN1D + Transformer sur signaux 12 leads
- **Wide Branch**: MLP sur features cliniques (NeuroKit2) + metadata
- **Fusion**: ConcatÃ©nation â†’ FC Head â†’ 71 codes SCP ou 5 superclasses

## ğŸš€ Installation rapide

```bash
# DÃ©pendances principales
pip install pandas numpy scikit-learn
pip install wfdb neurokit2
pip install torch torchvision
pip install xgboost
pip install tqdm
```

## ğŸ“‚ Structure du pipeline

```
PTB-XL Pipeline (7 steps)
â”‚
â”œâ”€â”€ STEP 1: Label Engineering
â”‚   â”œâ”€â”€ Input : ptbxl_database.csv, scp_statements.csv
â”‚   â”œâ”€â”€ Script: step1_label_engineering.py
â”‚   â””â”€â”€ Output: ptbxl_with_labels_expanded.csv (y__<CODE>, y_SUP__<CLASS>)
â”‚
â”œâ”€â”€ STEP 2: Signal Cleaning (NeuroKit2)
â”‚   â”œâ”€â”€ Input : records100/ (WFDB)
â”‚   â”œâ”€â”€ Script: step2_signal_cleaning.py
â”‚   â””â”€â”€ Output: cleaned_signals_100hz/*.npz (12Ã—1000)
â”‚
â”œâ”€â”€ STEP 3: Wide Features Extraction
â”‚   â”œâ”€â”€ Input : cleaned_signals_100hz/
â”‚   â”œâ”€â”€ Script: step3_wide_features_extraction.py
â”‚   â””â”€â”€ Output: ptbxl_wide_features.csv (~42 features)
â”‚
â”œâ”€â”€ STEP 4: Wide Preprocessing
â”‚   â”œâ”€â”€ Input : ptbxl_wide_features.csv
â”‚   â”œâ”€â”€ Script: step4_wide_preprocessing.py
â”‚   â””â”€â”€ Output: preprocessed_wide/W_*.npz (Train/Val/Test)
â”‚
â”œâ”€â”€ STEP 5: Architecture PyTorch
â”‚   â”œâ”€â”€ Script: step5_wide_deep_model.py (test)
â”‚   â””â”€â”€ Classes: WideDeepModel, DeepOnlyModel, WideOnlyModel
â”‚
â”œâ”€â”€ STEP 6: Training
â”‚   â”œâ”€â”€ Script: step6_training.py (config Ã©ditable)
â”‚   â””â”€â”€ Output: models/best_model.pth + results/
â”‚
â””â”€â”€ STEP 7: Baselines & Comparaison
    â”œâ”€â”€ Script: step7_baselines.py
    â””â”€â”€ Output: Tableau comparatif + analyse qualitÃ©
```

## âš¡ ExÃ©cution sÃ©quentielle

### STEP 1: Label Engineering (~1 minute)
```bash
python step1_label_engineering.py
```
**Sortie**: `ptbxl_with_labels_expanded.csv` avec colonnes:
- `y__<CODE>`: 71 labels binaires (ex: `y__NORM`, `y__MI`)
- `y_score__<CODE>`: scores originaux 0-100
- `y_SUP__<CLASS>`: 5 superclasses (NORM/MI/STTC/CD/HYP)

### STEP 2: Signal Cleaning (~20-30 minutes)
```bash
python step2_signal_cleaning.py
```
**Traitement**:
- Chargement WFDB (21,799 ECG)
- FIR bandpass 3-45 Hz par lead
- Z-score normalization
- Sauvegarde .npz compressÃ©

**Sortie**: `cleaned_signals_100hz/X_clean_*.npz` (~250 MB total)

**âš ï¸ MODE TEST**: Pour test rapide, Ã©diter ligne 77:
```python
SAMPLE_SIZE = 100  # Test sur 100 ECG seulement
```

### STEP 3: Wide Features Extraction (~10-15 minutes)
```bash
python step3_wide_features_extraction.py
```
**Features extraites (Lead II)**:
- R-peaks, HR, HRV (time domain)
- Intervalles P-QRS-T
- Entropies (sample, approximate)
- QualitÃ© (`rpeaks_ok`, `delineation_ok`)
- Metadata (age, sex, device, etc.)

**Sortie**: `ptbxl_wide_features.csv` (~42 colonnes)

### STEP 4: Wide Preprocessing (~1 minute)
```bash
python step4_wide_preprocessing.py
```
**Preprocessing** (fit sur Train uniquement):
- Imputation: mÃ©diane (num), "Unknown" (cat)
- Encodage: one-hot (device/site/nurse), label (heart_axis)
- Scaling: z-score sur numÃ©riques

**Sortie**: `preprocessed_wide/W_train.npz`, `W_val.npz`, `W_test.npz`

### STEP 5: Test Architecture (~10 secondes)
```bash
python step5_wide_deep_model.py
```
**VÃ©rification**: Forward pass OK, comptage paramÃ¨tres

### STEP 6: Training (3 configurations)

#### Configuration A: Deep Only
```python
# Ã‰diter step6_training.py:
class Config:
    model_type = 'deep_only'
    task_mode = '5superclass'  # ou '71codes'
    batch_size = 32
    num_epochs = 50
```
```bash
python step6_training.py
```

#### Configuration B: Wide Only (XGBoost)
```bash
python step7_baselines.py  # EntraÃ®ne XGBoost automatiquement
```

#### Configuration C: Wide+Deep â­ (RECOMMANDÃ‰)
```python
# Ã‰diter step6_training.py:
class Config:
    model_type = 'wide_deep'
    task_mode = '5superclass'
```
```bash
python step6_training.py
```

**DurÃ©e**: 2-5 heures (GPU recommandÃ©)

**Early stopping**: Patience 10 epochs sur Val AUC

### STEP 7: Comparaison & Analyse
```bash
python step7_baselines.py
```
**RÃ©sultats**:
- Tableau comparatif 3 baselines
- Analyse effet qualitÃ© signal (`RPeaks_ok`)

## ğŸ“Š RÃ©sultats attendus (CinC 2020)

| ModÃ¨le      | 5 Superclasses | 71 Codes SCP |
|-------------|----------------|--------------|
| Deep Only   | 0.85-0.88      | 0.78-0.82    |
| Wide Only   | 0.75-0.80      | 0.65-0.70    |
| **Wide+Deep** | **0.88-0.92** â­ | **0.80-0.85** â­ |

*AUC macro sur Test set*

## ğŸ¯ Choix de la tÃ¢che

### 5 Superclasses (recommandÃ© pour dÃ©buter)
- **NORM**: ECG normal
- **MI**: Myocardial Infarction
- **STTC**: ST/T Change
- **CD**: Conduction Disturbance
- **HYP**: Hypertrophy

**Avantages**: Moins de dÃ©sÃ©quilibre, entraÃ®nement plus rapide

### 71 Codes SCP (avancÃ©)
- Tous les codes diagnostiques PTB-XL
- Multi-label (plusieurs codes par ECG)

**Avantages**: GranularitÃ© fine, proche diagnostic clinique

## ğŸ”§ Configuration GPU/CPU

```python
# step6_training.py
class Config:
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # Si GPU limitÃ©:
    batch_size = 16  # au lieu de 32
```

**Temps CPU vs GPU (epoch)**:
- CPU: ~45 minutes/epoch
- GPU (RTX 3080): ~5 minutes/epoch

## ğŸ“ˆ Monitoring training

```python
# Dans step6_training.py, epoch loop affiche:
Epoch 15/50 | Train Loss: 0.1234 | Val Loss: 0.1456 | Val AUC: 0.8765
  â†’ Meilleur modÃ¨le sauvegardÃ© (AUC: 0.8765)
```

## ğŸ› DÃ©pannage

### Erreur: "neurokit2 not found"
```bash
pip install neurokit2
```

### Erreur: "torch not found"
```bash
# CPU
pip install torch torchvision

# GPU (CUDA 11.8)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### Erreur: "Out of Memory" (GPU)
```python
# RÃ©duire batch_size dans Config
batch_size = 16  # ou 8
```

### Signal cleaning trop lent
```python
# Mode test dans step2_signal_cleaning.py ligne 77
SAMPLE_SIZE = 100  # Test rapide
```

## ğŸ“¦ Outputs finaux

```
ptb-xl-dataset/
â”œâ”€â”€ ptbxl_with_labels_expanded.csv      (labels multi-label)
â”œâ”€â”€ label_config.json                    (config pour modÃ¨le)
â”œâ”€â”€ cleaned_signals_100hz/               (21,799 .npz ~250 MB)
â”œâ”€â”€ ptbxl_wide_features.csv             (features tabulaires)
â”œâ”€â”€ preprocessed_wide/                   (W_train/val/test.npz)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_model.pth                   (meilleur checkpoint)
â””â”€â”€ results/
    â””â”€â”€ results.json                     (mÃ©triques test)
```

## ğŸ“š RÃ©fÃ©rences

1. **PTB-XL Dataset**: Wagner et al. (2020), Scientific Data
2. **CinC Challenge 2020**: Classification of 12-lead ECGs
3. **NeuroKit2**: Makowski et al. (2021)
4. **Wide & Deep**: Cheng et al. (2016), Google

## ğŸ“ Citation

```bibtex
@article{wagner2020ptb,
  title={PTB-XL, a large publicly available electrocardiography dataset},
  author={Wagner, Patrick and Strodthoff, Nils and Bousseljot, Ralf-Dieter and Kreiseler, Dieter and Lunze, Fatima I and Samek, Wojciech and Schaeffter, Tobias},
  journal={Scientific data},
  volume={7},
  number={1},
  pages={154},
  year={2020}
}
```

## âœ… Checklist complÃ¨te

- [ ] Step 1: Label Engineering exÃ©cutÃ©
- [ ] Step 2: Signal Cleaning exÃ©cutÃ© (21,799 .npz crÃ©Ã©s)
- [ ] Step 3: Wide Features Extraction exÃ©cutÃ©
- [ ] Step 4: Wide Preprocessing exÃ©cutÃ©
- [ ] Step 5: Architecture testÃ©e (forward pass OK)
- [ ] Step 6A: Deep Only entraÃ®nÃ©
- [ ] Step 6B: Wide Only (XGBoost) entraÃ®nÃ©
- [ ] Step 6C: Wide+Deep entraÃ®nÃ© â­
- [ ] Step 7: Comparaison & analyse effectuÃ©e
- [ ] RÃ©sultats sauvegardÃ©s dans results/

## ğŸš€ Quick Start (rÃ©sumÃ©)

```bash
# 1. Labels
python step1_label_engineering.py

# 2-4. Preprocessing (30-40 min total)
python step2_signal_cleaning.py
python step3_wide_features_extraction.py
python step4_wide_preprocessing.py

# 5. Test architecture
python step5_wide_deep_model.py

# 6. Training Wide+Deep (Ã©diter Config avant)
python step6_training.py

# 7. Comparaison
python step7_baselines.py
```

**DurÃ©e totale**: 3-6 heures (selon CPU/GPU)

---

**Questions?** Consultez `step7_baselines.py` pour le guide complet d'exÃ©cution.
