"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 1 (ADAPTÃ‰): CHARGEMENT depuis PTB_XL_ML_Features_WITH_FILENAMES.xlsx
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Charge le fichier Excel prÃ©processÃ© qui contient dÃ©jÃ :
  - Features tabulaires (age, sex, quality_score, etc.)
  - Labels SCP encodÃ©s (scp_NORM, scp_IMI, etc.)
  - Superclasses (scp_superclass_NORM/MI/STTC/CD/HYP)
  - filename_lr et filename_hr pour accÃ¨s signaux

Sortie: dataset consolidÃ© train/val/test prÃªt pour le pipeline
"""

import pandas as pd
import numpy as np
import json
from pathlib import Path

print("=" * 100)
print("STEP 1 (ADAPTÃ‰): CHARGEMENT depuis Excel")
print("=" * 100)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. CHARGEMENT FICHIER EXCEL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n[1/5] Chargement fichier Excel...")

excel_file = 'PTB_XL_ML_Features_WITH_FILENAMES.xlsx'

# Charger les 3 sheets
df_train = pd.read_excel(excel_file, sheet_name='Train')
df_val = pd.read_excel(excel_file, sheet_name='Val')
df_test = pd.read_excel(excel_file, sheet_name='Test')

# DÃ©finir ecg_id comme index
df_train.set_index('ecg_id', inplace=True)
df_val.set_index('ecg_id', inplace=True)
df_test.set_index('ecg_id', inplace=True)

print(f"  âœ“ Train: {len(df_train):,} ECG Ã— {len(df_train.columns)} colonnes")
print(f"  âœ“ Val  : {len(df_val):,} ECG Ã— {len(df_val.columns)} colonnes")
print(f"  âœ“ Test : {len(df_test):,} ECG Ã— {len(df_test.columns)} colonnes")

# Combiner pour analyses globales
df_all = pd.concat([df_train, df_val, df_test])
print(f"  âœ“ Total: {len(df_all):,} ECG")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. IDENTIFIER COLONNES SCP et SUPERCLASSES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n[2/5] Identification colonnes labels...")

# Colonnes SCP individuelles
scp_cols = [col for col in df_all.columns if col.startswith('scp_') and not 'superclass' in col]
print(f"  âœ“ Codes SCP: {len(scp_cols)} colonnes")
print(f"    Exemples: {scp_cols[:10]}")

# Colonnes superclasses
superclass_cols = [col for col in df_all.columns if col.startswith('scp_superclass_')]
print(f"  âœ“ Superclasses: {len(superclass_cols)} colonnes")
print(f"    {superclass_cols}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. STATISTIQUES LABELS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n[3/5] Statistiques labels...")

# Top 10 codes SCP
scp_counts = df_all[scp_cols].sum().sort_values(ascending=False)
print(f"\n  Top 10 codes SCP les plus frÃ©quents:")
for i, (code, count) in enumerate(scp_counts.head(10).items(), 1):
    code_name = code.replace('scp_', '')
    pct = (count / len(df_all)) * 100
    print(f"    {i:2d}. {code_name:10s} : {int(count):5d} ({pct:5.2f}%)")

# Distribution superclasses
print(f"\n  Distribution superclasses:")
for sc_col in superclass_cols:
    sc_name = sc_col.replace('scp_superclass_', '')
    count = df_all[sc_col].sum()
    pct = (count / len(df_all)) * 100
    print(f"    {sc_name:5s} : {int(count):5d} ({pct:5.2f}%)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. CRÃ‰ER CONFIGURATION LABELS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n[4/5] CrÃ©ation configuration labels...")

# Extraire noms de codes (sans prÃ©fixe scp_)
scp_code_names = [col.replace('scp_', '') for col in scp_cols]
superclass_names = [col.replace('scp_superclass_', '') for col in superclass_cols]

label_config = {
    # Colonnes dans Excel
    'scp_cols_excel': scp_cols,
    'superclass_cols_excel': superclass_cols,
    
    # Noms de codes (pour compatibilitÃ©)
    'valid_codes': scp_code_names,
    'superclass_names': superclass_names,
    
    # Comptages
    'n_scp_codes': len(scp_cols),
    'n_superclasses': len(superclass_cols),
    'n_total_ecg': len(df_all),
    
    # Splits
    'n_train': len(df_train),
    'n_val': len(df_val),
    'n_test': len(df_test)
}

# Sauvegarder config
with open('label_config_from_excel.json', 'w') as f:
    json.dump(label_config, f, indent=2)

print(f"  âœ“ Configuration sauvegardÃ©e: label_config_from_excel.json")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. SAUVEGARDER DATASET CONSOLIDÃ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n[5/5] Sauvegarde datasets...")

# Ajouter colonne split pour identification
df_train['split'] = 'train'
df_val['split'] = 'val'
df_test['split'] = 'test'

# Combiner
df_consolidated = pd.concat([df_train, df_val, df_test])

# Sauvegarder CSV consolidÃ©
df_consolidated.to_csv('ptbxl_from_excel_consolidated.csv')
print(f"  âœ“ ptbxl_from_excel_consolidated.csv ({len(df_consolidated):,} lignes)")

# Sauvegarder aussi les splits sÃ©parÃ©s pour pipeline
df_train.to_csv('ptbxl_from_excel_train.csv')
df_val.to_csv('ptbxl_from_excel_val.csv')
df_test.to_csv('ptbxl_from_excel_test.csv')

print(f"  âœ“ ptbxl_from_excel_train.csv ({len(df_train):,} lignes)")
print(f"  âœ“ ptbxl_from_excel_val.csv ({len(df_val):,} lignes)")
print(f"  âœ“ ptbxl_from_excel_test.csv ({len(df_test):,} lignes)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. VÃ‰RIFIER PRÃ‰SENCE FILENAME_LR/HR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n[VÃ©rification]")

if 'filename_lr' in df_all.columns and 'filename_hr' in df_all.columns:
    print(f"  âœ“ filename_lr et filename_hr prÃ©sents")
    
    # VÃ©rifier chemins
    example_lr = df_all['filename_lr'].iloc[0]
    example_hr = df_all['filename_hr'].iloc[0]
    
    print(f"\n  Exemples:")
    print(f"    â€¢ filename_lr: {example_lr}")
    print(f"    â€¢ filename_hr: {example_hr}")
    
    # VÃ©rifier existence fichiers
    from pathlib import Path
    file_lr = Path(f"{example_lr}.dat")
    file_hr = Path(f"{example_hr}.dat")
    
    if file_lr.exists():
        print(f"    âœ“ Fichier LR existe")
    else:
        print(f"    âœ— Fichier LR n'existe pas")
    
    if file_hr.exists():
        print(f"    âœ“ Fichier HR existe")
    else:
        print(f"    âœ— Fichier HR n'existe pas")
else:
    print(f"  âœ— filename_lr/hr manquants!")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7. RÃ‰SUMÃ‰ FINAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n" + "=" * 100)
print("RÃ‰SUMÃ‰ FINAL")
print("=" * 100)

print(f"\nğŸ“Š DONNÃ‰ES CHARGÃ‰ES:")
print(f"  â€¢ Total ECG           : {len(df_all):,}")
print(f"  â€¢ Train / Val / Test  : {len(df_train):,} / {len(df_val):,} / {len(df_test):,}")
print(f"  â€¢ Features totales    : {len(df_all.columns)}")

print(f"\nğŸ·ï¸  LABELS:")
print(f"  â€¢ Codes SCP          : {len(scp_cols)}")
print(f"  â€¢ Superclasses       : {len(superclass_cols)}")

print(f"\nğŸ“‚ FICHIERS GÃ‰NÃ‰RÃ‰S:")
print(f"  â€¢ ptbxl_from_excel_consolidated.csv")
print(f"  â€¢ ptbxl_from_excel_train/val/test.csv")
print(f"  â€¢ label_config_from_excel.json")

print(f"\nâœ… STEP 1 TERMINÃ‰ (depuis Excel)")
print(f"   Prochaine Ã©tape: step2_signal_cleaning_adapted.py")
print("=" * 100)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# APERÃ‡U DONNÃ‰ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\nğŸ“‹ APERÃ‡U COLONNES:")
print(f"\nFeatures numÃ©riques:")
numeric_cols = df_all.select_dtypes(include=[np.number]).columns.tolist()
numeric_cols = [c for c in numeric_cols if not c.startswith('scp_')]
print(f"  {numeric_cols[:15]}")

print(f"\nFeatures catÃ©gorielles:")
cat_cols = df_all.select_dtypes(include=['object', 'bool']).columns.tolist()
print(f"  {cat_cols[:10]}")

print(f"\nLabels SCP (premiers 10):")
print(f"  {scp_cols[:10]}")

print(f"\nSuperclasses:")
print(f"  {superclass_cols}")
