"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXEMPLE D'UTILISATION DU MODÃˆLE WIDE+DEEP PURE
AVEC FORMAT ORIGINAL DU DATASET PTB-XL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ce script lit les fichiers ECG dans le FORMAT ORIGINAL du dataset PTB-XL:
  - Fichiers WFDB: records100/XXXXX/XXXXX_lr.dat et .hea
  - Fichier CSV: ptbxl_database.csv (mÃ©tadonnÃ©es et features)

STRUCTURE DU DATASET PTB-XL:
  ptb-xl-dataset/
  â”œâ”€â”€ records100/           â† Signaux ECG 100Hz (format WFDB)
  â”‚   â”œâ”€â”€ 00000/
  â”‚   â”‚   â”œâ”€â”€ 00001_lr.dat  â† DonnÃ©es binaires
  â”‚   â”‚   â”œâ”€â”€ 00001_lr.hea  â† Header (mÃ©tadonnÃ©es)
  â”‚   â”‚   â”œâ”€â”€ 00002_lr.dat
  â”‚   â”‚   â””â”€â”€ ...
  â”‚   â”œâ”€â”€ 01000/
  â”‚   â””â”€â”€ ...
  â”œâ”€â”€ ptbxl_database.csv    â† MÃ©tadonnÃ©es + labels
  â””â”€â”€ scp_statements.csv    â† Mapping codes SCP â†’ superclasses

INPUTS DU MODÃˆLE:
  1. Signal ECG: (batch, 12, 1000) - 12 dÃ©rivations, 10s @ 100Hz
  2. Wide Features: (batch, 32) - 32 features cliniques

OUTPUT:
  - ProbabilitÃ©s: (batch, 5) - [NORM, MI, STTC, CD, HYP]

Auteur: Pipeline Wide+Deep PTB-XL
Date: Janvier 2026
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VÃ‰RIFICATION DES DÃ‰PENDANCES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("="*70)
print("  VÃ‰RIFICATION DES DÃ‰PENDANCES")
print("="*70)

try:
    import wfdb
    print(f"  âœ“ wfdb version {wfdb.__version__}")
except ImportError:
    print("  âœ— wfdb non installÃ© â†’ pip install wfdb")
    exit(1)

try:
    import neurokit2 as nk
    print(f"  âœ“ neurokit2 version {nk.__version__}")
except ImportError:
    print("  âœ— neurokit2 non installÃ© â†’ pip install neurokit2")
    exit(1)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. ARCHITECTURE DU MODÃˆLE (copie autonome)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class WideDeepModel(nn.Module):
    """
    Architecture Wide+Deep pour classification ECG multi-label.
    Total: 11,561,573 paramÃ¨tres
    """
    
    def __init__(self, num_wide_features=32, num_classes=5):
        super().__init__()
        
        # Deep branch - CNN (6 blocs)
        self.conv_layers = nn.Sequential(
            nn.Conv1d(12, 64, kernel_size=14, padding=7),
            nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),
            nn.Conv1d(64, 128, kernel_size=14, padding=7),
            nn.BatchNorm1d(128), nn.ReLU(), nn.MaxPool1d(2),
            nn.Conv1d(128, 256, kernel_size=10, padding=5),
            nn.BatchNorm1d(256), nn.ReLU(), nn.MaxPool1d(2),
            nn.Conv1d(256, 256, kernel_size=10, padding=5),
            nn.BatchNorm1d(256), nn.ReLU(), nn.MaxPool1d(2),
            nn.Conv1d(256, 512, kernel_size=10, padding=5),
            nn.BatchNorm1d(512), nn.ReLU(), nn.MaxPool1d(2),
            nn.Conv1d(512, 512, kernel_size=10, padding=5),
            nn.BatchNorm1d(512), nn.ReLU(), nn.AdaptiveAvgPool1d(1)
        )
        
        # Deep branch - Transformer (8 layers)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=256, nhead=8, dim_feedforward=1024,
            dropout=0.1, batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=8)
        self.cnn_to_transformer = nn.Linear(512, 256)
        
        self.deep_fc = nn.Sequential(
            nn.Linear(256, 128), nn.ReLU(), nn.Dropout(0.1),
            nn.Linear(128, 64)
        )
        
        # Wide branch
        self.wide_fc = nn.Sequential(
            nn.Linear(num_wide_features, 64), nn.ReLU(), nn.Dropout(0.1),
            nn.Linear(64, 32)
        )
        
        # Fusion
        self.fusion = nn.Sequential(
            nn.Linear(64 + 32, 128), nn.ReLU(), nn.Dropout(0.1),
            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.1),
            nn.Linear(64, num_classes)
        )
    
    def forward(self, signal, wide_features):
        x = self.conv_layers(signal).squeeze(-1)
        x = self.cnn_to_transformer(x).unsqueeze(1)
        x = self.transformer(x).mean(dim=1)
        deep_out = self.deep_fc(x)
        wide_out = self.wide_fc(wide_features)
        combined = torch.cat([deep_out, wide_out], dim=1)
        return self.fusion(combined)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Chemin vers le modÃ¨le
MODEL_PATH = 'model_wide_deep_pure_FIXED.pth'

# Chemins vers le dataset PTB-XL (format original)
RECORDS_DIR = Path('records100')           # Signaux WFDB
DATABASE_CSV = Path('ptbxl_database.csv')  # MÃ©tadonnÃ©es

# Device
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Classes
CLASS_NAMES = ['NORM', 'MI', 'STTC', 'CD', 'HYP']
CLASS_DESCRIPTIONS = {
    'NORM': 'ECG Normal',
    'MI': 'Infarctus du Myocarde',
    'STTC': 'Changements ST/T',
    'CD': 'Troubles de Conduction',
    'HYP': 'Hypertrophie'
}

# Les 12 dÃ©rivations ECG standard
LEAD_NAMES = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. FONCTIONS POUR LIRE LE FORMAT ORIGINAL PTB-XL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_ecg_from_wfdb(ecg_id, records_dir='records100', sampling_rate=100):
    """
    Charge un signal ECG depuis le format WFDB original du dataset PTB-XL.
    
    Structure des fichiers:
        records100/
        â”œâ”€â”€ 00000/
        â”‚   â”œâ”€â”€ 00001_lr.dat    â† DonnÃ©es binaires du signal
        â”‚   â”œâ”€â”€ 00001_lr.hea    â† Header avec mÃ©tadonnÃ©es
        â”‚   â””â”€â”€ ...
        â”œâ”€â”€ 01000/
        â”‚   â”œâ”€â”€ 01001_lr.dat
        â”‚   â””â”€â”€ ...
        â””â”€â”€ ...
    
    Args:
        ecg_id: int - Identifiant ECG (1 Ã  21837)
        records_dir: str - Chemin vers records100/
        sampling_rate: int - 100Hz pour records100, 500Hz pour records500
        
    Returns:
        signal: numpy array (12, 1000) - 12 dÃ©rivations Ã— 1000 samples
    """
    # Construire le chemin du fichier
    # Format: records100/XXXXX/XXXXX_lr oÃ¹ XXXXX est le dossier (arrondi Ã  1000)
    folder = f"{(ecg_id // 1000) * 1000:05d}"
    filename = f"{ecg_id:05d}_lr"
    record_path = Path(records_dir) / folder / filename
    
    print(f"\n[WFDB] Lecture du fichier ECG...")
    print(f"  Chemin: {record_path}.dat / .hea")
    
    # VÃ©rifier que les fichiers existent
    if not Path(f"{record_path}.dat").exists():
        raise FileNotFoundError(f"Fichier non trouvÃ©: {record_path}.dat")
    
    # Lire le signal avec wfdb
    record = wfdb.rdrecord(str(record_path))
    
    # record.p_signal contient le signal: shape (1000, 12) pour 100Hz Ã— 10s
    signal = record.p_signal  # numpy array (1000, 12)
    
    print(f"  Format brut: {signal.shape} (samples Ã— leads)")
    print(f"  FrÃ©quence: {record.fs} Hz")
    print(f"  DurÃ©e: {signal.shape[0] / record.fs:.1f} secondes")
    print(f"  DÃ©rivations: {record.sig_name}")
    
    # Transposer pour avoir (12, 1000) comme attendu par le modÃ¨le
    signal = signal.T  # (12, 1000)
    
    print(f"  Format transposÃ©: {signal.shape} (leads Ã— samples)")
    
    return signal.astype(np.float32)


def clean_ecg_signal(signal, sampling_rate=100):
    """
    Nettoie le signal ECG avec filtrage et normalisation.
    Identique au prÃ©traitement utilisÃ© pendant l'entraÃ®nement.
    
    Args:
        signal: numpy array (12, 1000)
        sampling_rate: int - frÃ©quence d'Ã©chantillonnage
        
    Returns:
        cleaned: numpy array (12, 1000) - signal nettoyÃ©
    """
    print(f"\n[CLEANING] Nettoyage du signal ECG...")
    
    cleaned = np.zeros_like(signal)
    
    for lead_idx in range(12):
        lead_signal = signal[lead_idx, :]
        
        # Interpoler les NaN si prÃ©sents
        if np.isnan(lead_signal).any():
            lead_signal = pd.Series(lead_signal).interpolate(method='linear').fillna(0).values
        
        # Filtre FIR bandpass 3-45 Hz (standard ECG clinique)
        try:
            lead_clean = nk.ecg_clean(
                lead_signal, 
                sampling_rate=sampling_rate,
                method='neurokit'
            )
        except:
            lead_clean = lead_signal
        
        # Normalisation z-score par dÃ©rivation
        mean_val = np.mean(lead_clean)
        std_val = np.std(lead_clean)
        
        if std_val > 1e-6:
            lead_clean = (lead_clean - mean_val) / std_val
        else:
            lead_clean = lead_clean - mean_val
        
        cleaned[lead_idx, :] = lead_clean
    
    print(f"  âœ“ Filtre FIR bandpass 3-45 Hz appliquÃ©")
    print(f"  âœ“ Normalisation z-score par dÃ©rivation")
    print(f"  Shape finale: {cleaned.shape}")
    
    return cleaned.astype(np.float32)


def load_wide_features_from_csv(ecg_id, csv_path='ptbxl_database.csv'):
    """
    Extrait les 32 features Wide depuis ptbxl_database.csv.
    
    Le fichier CSV contient les colonnes:
        - ecg_id: identifiant unique
        - patient_id, age, sex, height, weight
        - recording_date, validated_by, etc.
        - Intervalles: rr_interval, pr_interval, qrs_duration, qt_interval, qtc_interval
        - Axes: p_axis, qrs_axis, t_axis
        - Amplitudes extraites
        
    Args:
        ecg_id: int - Identifiant ECG
        csv_path: str - Chemin vers ptbxl_database.csv
        
    Returns:
        features: numpy array (32,) - 32 features normalisÃ©es
    """
    print(f"\n[CSV] Lecture des features depuis {csv_path}...")
    
    # Charger le CSV
    df = pd.read_csv(csv_path, index_col='ecg_id')
    
    if ecg_id not in df.index:
        raise ValueError(f"ECG ID {ecg_id} non trouvÃ© dans {csv_path}")
    
    row = df.loc[ecg_id]
    
    # Extraire les features disponibles
    # Note: Adapter selon les colonnes rÃ©ellement prÃ©sentes dans votre CSV
    features = []
    
    # DÃ©mographiques
    features.append(row.get('age', 50) / 100)  # Normaliser Ã¢ge
    features.append(1 if row.get('sex', 0) == 1 else 0)  # 1=M, 0=F
    features.append(row.get('height', 170) / 200)  # Normaliser hauteur
    features.append(row.get('weight', 70) / 150)  # Normaliser poids
    
    # Intervalles ECG (si disponibles)
    # Ces valeurs peuvent Ãªtre extraites automatiquement ou Ãªtre dans le CSV
    default_intervals = {
        'rr_interval': 0.85,
        'pr_interval': 0.16,
        'qrs_duration': 0.09,
        'qt_interval': 0.40,
        'qtc_interval': 0.42
    }
    
    for key, default in default_intervals.items():
        val = row.get(key, default)
        if pd.isna(val):
            val = default
        features.append(float(val))
    
    # Axes
    for axis in ['p_axis', 'qrs_axis', 't_axis']:
        val = row.get(axis, 0)
        if pd.isna(val):
            val = 0
        features.append(float(val) / 180)  # Normaliser Ã  [-1, 1]
    
    # ComplÃ©ter jusqu'Ã  32 features avec des valeurs par dÃ©faut
    while len(features) < 32:
        features.append(0.0)
    
    features = np.array(features[:32], dtype=np.float32)
    
    print(f"  âœ“ {len(features)} features extraites")
    print(f"  Shape: {features.shape}")
    
    return features


def load_wide_features_from_npz(ecg_id, wide_dir='wide_features_clean'):
    """
    Alternative: Charge les features depuis les fichiers .npz prÃ©-calculÃ©s.
    
    Args:
        ecg_id: int
        wide_dir: str
        
    Returns:
        features: numpy array (32,)
    """
    for split in ['test', 'val', 'train']:
        wide_path = Path(wide_dir) / f'W_pure_{split}.npz'
        
        if wide_path.exists():
            data = np.load(wide_path)
            ecg_ids = data['ecg_ids']
            
            if ecg_id in ecg_ids:
                idx = np.where(ecg_ids == ecg_id)[0][0]
                features = data['W'][idx]
                print(f"\n[NPZ] Features chargÃ©es depuis {split}")
                print(f"  Shape: {features.shape}")
                return features.astype(np.float32)
    
    return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. FONCTION DE PRÃ‰DICTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def predict(model, signal, wide_features, device):
    """
    Effectue une prÃ©diction avec le modÃ¨le.
    
    Args:
        model: WideDeepModel
        signal: (12, 1000) ou (batch, 12, 1000)
        wide_features: (32,) ou (batch, 32)
        device: torch device
        
    Returns:
        probabilities: (5,) ou (batch, 5)
    """
    # Ajouter dimension batch si nÃ©cessaire
    if signal.ndim == 2:
        signal = signal[np.newaxis, ...]
    if wide_features.ndim == 1:
        wide_features = wide_features[np.newaxis, ...]
    
    # Tensors
    signal_t = torch.from_numpy(signal).float().to(device)
    wide_t = torch.from_numpy(wide_features).float().to(device)
    
    # PrÃ©diction
    with torch.no_grad():
        logits = model(signal_t, wide_t)
        probs = torch.sigmoid(logits).cpu().numpy()
    
    return probs


def display_results(probabilities, threshold=0.5):
    """Affiche les rÃ©sultats de prÃ©diction."""
    
    print("\n" + "="*65)
    print("                      RÃ‰SULTATS")
    print("="*65)
    
    probs = probabilities[0] if probabilities.ndim == 2 else probabilities
    
    print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚  Classe  â”‚ ProbabilitÃ©â”‚          Description                â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    
    for name, prob in zip(CLASS_NAMES, probs):
        status = "âœ“" if prob >= threshold else " "
        bar = "â–ˆ" * int(prob * 15) + "â–‘" * (15 - int(prob * 15))
        print(f"â”‚ {status} {name:<6} â”‚ {prob*100:>6.2f}% {bar} â”‚ {CLASS_DESCRIPTIONS[name]:<35} â”‚")
    
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    # Diagnostic
    detected = [CLASS_NAMES[i] for i, p in enumerate(probs) if p >= threshold]
    
    print(f"\nğŸ“‹ DIAGNOSTIC (seuil = {threshold*100:.0f}%):")
    if detected:
        for cls in detected:
            print(f"   âœ“ {cls}: {CLASS_DESCRIPTIONS[cls]}")
    else:
        print("   â†’ Aucune pathologie dÃ©tectÃ©e au-dessus du seuil")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. EXEMPLE D'UTILISATION PRINCIPAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    
    print("\n" + "="*70)
    print("  EXEMPLE D'UTILISATION AVEC FORMAT ORIGINAL PTB-XL")
    print("="*70)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ã‰TAPE 1: Charger le modÃ¨le
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n" + "â”€"*70)
    print("  Ã‰TAPE 1: CHARGEMENT DU MODÃˆLE")
    print("â”€"*70)
    
    model = WideDeepModel(num_wide_features=32, num_classes=5)
    
    if Path(MODEL_PATH).exists():
        checkpoint = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=True)
        model.load_state_dict(checkpoint)
        print(f"\n[MODEL] âœ“ ModÃ¨le chargÃ©: {MODEL_PATH}")
    else:
        print(f"\n[MODEL] âš  ModÃ¨le non trouvÃ©: {MODEL_PATH}")
        print("        Utilisation du modÃ¨le non-entraÃ®nÃ© (dÃ©mo)")
    
    model.to(DEVICE)
    model.eval()
    print(f"[MODEL] Device: {DEVICE}")
    print(f"[MODEL] ParamÃ¨tres: {sum(p.numel() for p in model.parameters()):,}")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ã‰TAPE 2: Choisir un ECG du dataset
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n" + "â”€"*70)
    print("  Ã‰TAPE 2: SÃ‰LECTION D'UN ECG")
    print("â”€"*70)
    
    # Choisir un ECG ID (entre 1 et 21837)
    ECG_ID = 1  # Exemple: premier ECG du dataset
    
    print(f"\n[ECG] ID sÃ©lectionnÃ©: {ECG_ID}")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ã‰TAPE 3: Charger le signal ECG (format WFDB original)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n" + "â”€"*70)
    print("  Ã‰TAPE 3: CHARGEMENT DU SIGNAL ECG (FORMAT WFDB)")
    print("â”€"*70)
    
    print("""
    STRUCTURE DES FICHIERS WFDB:
    â”œâ”€â”€ records100/00000/00001_lr.dat  â† DonnÃ©es binaires (signal)
    â””â”€â”€ records100/00000/00001_lr.hea  â† Header (mÃ©tadonnÃ©es)
    
    Contenu du .hea:
        - FrÃ©quence d'Ã©chantillonnage: 100 Hz
        - Nombre de samples: 1000 (10 secondes)
        - Nombre de dÃ©rivations: 12
        - Noms: I, II, III, aVR, aVL, aVF, V1, V2, V3, V4, V5, V6
    """)
    
    try:
        # Charger le signal brut
        signal_raw = load_ecg_from_wfdb(ECG_ID, RECORDS_DIR)
        
        # Nettoyer le signal (filtrage + normalisation)
        signal_clean = clean_ecg_signal(signal_raw)
        
    except FileNotFoundError as e:
        print(f"\n[WARN] {e}")
        print("[WARN] GÃ©nÃ©ration d'un signal simulÃ© pour la dÃ©mo...")
        
        # Signal simulÃ© si fichiers non disponibles
        t = np.linspace(0, 10, 1000)
        signal_clean = np.zeros((12, 1000), dtype=np.float32)
        for i in range(12):
            signal_clean[i] = np.sin(2 * np.pi * 1.2 * t) + 0.05 * np.random.randn(1000)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ã‰TAPE 4: Charger les features Wide
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n" + "â”€"*70)
    print("  Ã‰TAPE 4: CHARGEMENT DES FEATURES WIDE")
    print("â”€"*70)
    
    print("""
    OPTIONS DE CHARGEMENT:
    1. Depuis ptbxl_database.csv (format original)
    2. Depuis wide_features_clean/*.npz (prÃ©-calculÃ©es)
    """)
    
    # Essayer d'abord les features prÃ©-calculÃ©es
    wide_features = load_wide_features_from_npz(ECG_ID)
    
    if wide_features is None:
        try:
            wide_features = load_wide_features_from_csv(ECG_ID)
        except Exception as e:
            print(f"\n[WARN] {e}")
            print("[WARN] GÃ©nÃ©ration de features simulÃ©es...")
            wide_features = np.random.randn(32).astype(np.float32) * 0.1
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ã‰TAPE 5: RÃ©sumÃ© des inputs
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n" + "â”€"*70)
    print("  Ã‰TAPE 5: RÃ‰SUMÃ‰ DES INPUTS")
    print("â”€"*70)
    
    print(f"""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           INPUT 1: SIGNAL ECG                       â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  Source: records100/{(ECG_ID//1000)*1000:05d}/{ECG_ID:05d}_lr.dat/.hea{' '*(22-len(str(ECG_ID)))}â”‚
    â”‚  Shape: {str(signal_clean.shape):<57} â”‚
    â”‚  Type: {str(signal_clean.dtype):<58} â”‚
    â”‚  Min/Max: [{signal_clean.min():.3f}, {signal_clean.max():.3f}]{' '*43}â”‚
    â”‚  DÃ©rivations: I, II, III, aVR, aVL, aVF, V1, V2, V3, V4, V5, V6     â”‚
    â”‚  Samples: 1000 (10 secondes @ 100Hz)                                â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                         INPUT 2: WIDE FEATURES                      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  Source: ptbxl_database.csv ou wide_features_clean/*.npz            â”‚
    â”‚  Shape: {str(wide_features.shape):<57} â”‚
    â”‚  Type: {str(wide_features.dtype):<58} â”‚
    â”‚  Contenu: intervalles, amplitudes, dÃ©mographiques, qualitÃ©         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ã‰TAPE 6: PrÃ©diction
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n" + "â”€"*70)
    print("  Ã‰TAPE 6: PRÃ‰DICTION")
    print("â”€"*70)
    
    probabilities = predict(model, signal_clean, wide_features, DEVICE)
    
    print(f"""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                              OUTPUT                                 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  Shape: {str(probabilities.shape):<57} â”‚
    â”‚  Type: {str(probabilities.dtype):<58} â”‚
    â”‚  Valeurs: [{', '.join([f'{p:.3f}' for p in probabilities[0]])}]{' '*20}â”‚
    â”‚  Classes: NORM, MI, STTC, CD, HYP                                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ã‰TAPE 7: Afficher les rÃ©sultats
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    display_results(probabilities, threshold=0.5)
    
    print("\n" + "="*70)
    print("  FIN DE L'EXEMPLE")
    print("="*70)
